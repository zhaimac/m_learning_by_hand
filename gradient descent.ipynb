{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thermal-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x=np.array([1,2,3,4,5])\n",
    "y=np.array([2,4,6,8,10])\n",
    "\n",
    "w=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "skilled-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x,w):\n",
    "    return w*x\n",
    "\n",
    "# MSE\n",
    "def loss(y, y_hat):\n",
    "    return ((y-y_hat)**2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "expressed-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = forward(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "agreed-marketing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-andorra",
   "metadata": {},
   "source": [
    "# gradient descent\n",
    "\n",
    "MSE = 1/N*(w*x - y)**2\n",
    "\n",
    "dj/dw = 1/N * 2x(w*x -y) = 1/N * 2x(y_hat -y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minute-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x, y, y_hat):\n",
    "    return np.dot(2*x, y_hat-y ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alert-threshold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of 20 is 11.0 grad is -110.0\n",
      "The loss of 20 is 0.11000000000000017 grad is 11.000000000000007\n",
      "The loss of 20 is 0.001100000000000018 grad is -1.100000000000009\n",
      "The loss of 20 is 1.0999999999997221e-05 grad is 0.10999999999998611\n",
      "The loss of 20 is 1.1000000000013564e-07 grad is -0.011000000000006782\n",
      "The loss of 20 is 1.10000000001086e-09 grad is 0.00110000000000543\n",
      "The loss of 20 is 1.099999999836777e-11 grad is -0.00010999999999183885\n",
      "The loss of 20 is 1.0999999960442551e-13 grad is 1.0999999980221276e-05\n",
      "The loss of 20 is 1.1000000043931324e-15 grad is -1.1000000021965661e-06\n",
      "The loss of 20 is 1.1000001820288237e-17 grad is 1.1000000910144081e-07\n",
      "The loss of 20 is 1.1000001820288237e-19 grad is -1.1000000910144081e-08\n",
      "The loss of 20 is 1.1000179457564597e-21 grad is 1.100008972798605e-09\n",
      "The loss of 20 is 1.1001955899747951e-23 grad is -1.1000977906405751e-10\n",
      "The loss of 20 is 1.0978880929409332e-25 grad is 1.098943158694965e-11\n",
      "The loss of 20 is 1.0964870759732607e-27 grad is -1.0982326159592048e-12\n",
      "The loss of 20 is 7.257520328033308e-30 grad is 8.881784197001252e-14\n",
      "The loss of 20 is 0.0 grad is 0.0\n",
      "The loss of 20 is 0.0 grad is 0.0\n",
      "The loss of 20 is 0.0 grad is 0.0\n",
      "The loss of 20 is 0.0 grad is 0.0\n"
     ]
    }
   ],
   "source": [
    "w=1\n",
    "epoch = 20\n",
    "for ep in range(epoch):\n",
    "    y_hat = forward(x, w)\n",
    "    \n",
    "    \n",
    "    l = loss(y, y_hat)\n",
    "    dw = gradient(x, y, y_hat)\n",
    "    print(f\"The loss of {epoch} is {l} grad is {dw}\")\n",
    "    \n",
    "    w -= 0.01*(dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "narrow-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "x2= np.array([5,2,3,4,10])\n",
    "y2_hat = w * x2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "outdoor-butter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type        Data/Info\n",
      "--------------------------------\n",
      "dw         float64     0.0\n",
      "ep         int         19\n",
      "epoch      int         20\n",
      "forward    function    <function forward at 0x7f67be285160>\n",
      "gradient   function    <function gradient at 0x7f67be285ca0>\n",
      "l          float64     0.0\n",
      "loss       function    <function loss at 0x7f67be2851f0>\n",
      "np         module      <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
      "w          float64     2.0\n",
      "x          ndarray     5: 5 elems, type `int64`, 40 bytes\n",
      "x2         ndarray     5: 5 elems, type `int64`, 40 bytes\n",
      "y          ndarray     5: 5 elems, type `int64`, 40 bytes\n",
      "y2_hat     ndarray     5: 5 elems, type `float64`, 40 bytes\n",
      "y_hat      ndarray     5: 5 elems, type `float64`, 40 bytes\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-university",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
